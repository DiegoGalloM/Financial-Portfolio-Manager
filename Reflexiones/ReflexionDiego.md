# Diego Esteban Gallo Mora - A00843874
## ¿Cómo usamos o no usamos copilot?
En mi caso, fui el encargado del análisis de los datos del CSV ingresado. Esto significa que las estadísticas generales y la matemática implicada para eso fue hecho por mí. La parte de las ecuaciones matemáticas fue hecho por mí, sin la necesidad de usar copilot. Pero al momento de realizar las gráficas de ASCII, fue bastante complicado para mí. El tema del diseño y la muestra de la separación de los datos fue hecho con apoyo de Copilot. Adicionalmente, Copilot permitió organizar las funciones de forma estructurada una vez que ya estaban escritas, pero que se pudiera entender de forma uniforme.

## ¿Qué partes fueron hechas por el equipo?
Todo el equipo trabajó junto al momento de implementar las distintas partes de las clases al main. En el menú principal hicimos reuniones donde discutimos cómo organizar las opciones y qué funcionalidad debía ir en cada una. También trabajamos en conjunto para decidir la estructura de carpetas y cómo manejar los archivos CSV y los reportes generados. La integración entre las diferentes clases fue un trabajo colaborativo donde cada uno aportó desde su especialidad pero siempre verificando que todo funcionara correctamente en conjunto 

## ¿Cómo validaron los resultados?:
Al finalizar el proyecto pudimos validar todos los datos ingresados al momento de desplegar los tipos de dato de las diferentes columnas para cada una de las bases de datos ingresadas. Asimismo, al momento de desplegar N filas de cada base de datos, o columnas en específico, pudimos comparar con las bases de datos en sí para asegurarnos que coincidian a la perfección.

## ¿Qué aprendimos del proceso?
Aprendimos a trabajar en equipo en un lenguaje de programación diferente. Dado que C++ requiere de un compilador, fue complicado al comienzo dado que teníamos ciertos snippets y configuraciones distintas que influían al momento de compilar y ejecutar el código con cada intento. También aprendimos la importancia de la detección automática de tipos de datos y cómo manejar diferentes estructuras de CSV de forma dinámica. El manejo de errores y la validación de entrada fueron aspectos que mejoramos bastante durante el desarrollo. Además, comprendimos mejor cómo organizar un proyecto grande con múltiples archivos y cómo estructurar el código para que sea mantenible y escalable.

## ¿Qué riesgos detectamos?
Detectamos que al trabajar con archivos CSV muy grandes, como el de stocks con más de 600 mil registros, el tiempo de procesamiento podía ser considerable y afectar la experiencia del usuario. Por eso implementamos una barra de progreso para dar feedback visual. También identificamos riesgos relacionados con la compatibilidad entre diferentes compiladores y versiones de C++, especialmente con características de C++20 como los tipos de fecha. Otro riesgo fue el manejo de rutas de archivos en diferentes sistemas operativos, que resolvimos usando la librería filesystem de C++. Finalmente, vimos que la detección automática de tipos podía fallar con datos ambiguos o mal formateados, por lo que agregamos validaciones y manejo de excepciones robusto.
